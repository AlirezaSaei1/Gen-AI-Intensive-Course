{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1c904d",
   "metadata": {
    "papermill": {
     "duration": 0.004892,
     "end_time": "2025-04-15T19:39:19.941193",
     "exception": false,
     "start_time": "2025-04-15T19:39:19.936301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Autonomous Multi-Agent System for Enhanced Automotive User Experience\n",
    "\n",
    "#### Capstone Project - Kaggle 5-Day Generative AI Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8ccac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:39:19.950963Z",
     "iopub.status.busy": "2025-04-15T19:39:19.950252Z",
     "iopub.status.idle": "2025-04-15T19:40:46.149910Z",
     "shell.execute_reply": "2025-04-15T19:40:46.148702Z"
    },
    "papermill": {
     "duration": 86.206288,
     "end_time": "2025-04-15T19:40:46.151617",
     "exception": false,
     "start_time": "2025-04-15T19:39:19.945329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m668.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting chromadb\r\n",
      "  Downloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\r\n",
      "Collecting build>=1.0.3 (from chromadb)\r\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.3)\r\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\r\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\r\n",
      "Collecting fastapi==0.115.9 (from chromadb)\r\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\r\n",
      "Collecting posthog>=2.4.0 (from chromadb)\r\n",
      "  Downloading posthog-3.24.2-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\r\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\r\n",
      "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\r\n",
      "Collecting pypika>=0.48.9 (from chromadb)\r\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\r\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\r\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\r\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\r\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\r\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\r\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\r\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\r\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\r\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\r\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\r\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\r\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\r\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\r\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\r\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\r\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\r\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\r\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\r\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\r\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\r\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\r\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\r\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\r\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\r\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\r\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\r\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\r\n",
      "Downloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\r\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\r\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\r\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\r\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\r\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading posthog-3.24.2-py2.py3-none-any.whl (90 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\r\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\r\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\r\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=cd5b65fd63f91b199b7c39b4be3f4a9f59bd60e5e815c7c5ae7505dcc4d2f103\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\r\n",
      "Successfully built pypika\r\n",
      "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, opentelemetry-util-http, mmh3, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, onnxruntime, chroma-hnswlib, chromadb\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: opentelemetry-api\r\n",
      "    Found existing installation: opentelemetry-api 1.16.0\r\n",
      "    Uninstalling opentelemetry-api-1.16.0:\r\n",
      "      Successfully uninstalled opentelemetry-api-1.16.0\r\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\r\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\r\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\r\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\r\n",
      "  Attempting uninstall: opentelemetry-sdk\r\n",
      "    Found existing installation: opentelemetry-sdk 1.16.0\r\n",
      "    Uninstalling opentelemetry-sdk-1.16.0:\r\n",
      "      Successfully uninstalled opentelemetry-sdk-1.16.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.4 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-3.24.2 protobuf-5.29.4 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3 uvicorn-0.34.1 uvloop-0.21.0 watchfiles-1.0.5\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "opentelemetry-proto 1.32.1 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy kfp jupyterlab google-generativeai tensorflow-hub 2>/dev/null\n",
    "!pip install -U -q langchain langchain-google-genai langgraph google-cloud-aiplatform pandas scikit-learn \"langchain-community>=0.2.7\" \"langchain-core>=0.2.19\"\n",
    "!pip install -U -q google-cloud-speech\n",
    "!pip install chromadb\n",
    "!pip install \"protobuf==3.20.3\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0007d0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:40:46.176297Z",
     "iopub.status.busy": "2025-04-15T19:40:46.175209Z",
     "iopub.status.idle": "2025-04-15T19:41:03.121301Z",
     "shell.execute_reply": "2025-04-15T19:41:03.120309Z"
    },
    "papermill": {
     "duration": 16.960414,
     "end_time": "2025-04-15T19:41:03.123069",
     "exception": false,
     "start_time": "2025-04-15T19:40:46.162655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "import uuid\n",
    "import math\n",
    "import heapq\n",
    "from collections.abc import Iterable\n",
    "from random import randint\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "from langchain_community.vectorstores.matching_engine import MatchingEngine\n",
    "\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb5c1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:03.145699Z",
     "iopub.status.busy": "2025-04-15T19:41:03.145129Z",
     "iopub.status.idle": "2025-04-15T19:41:03.329090Z",
     "shell.execute_reply": "2025-04-15T19:41:03.328123Z"
    },
    "papermill": {
     "duration": 0.197032,
     "end_time": "2025-04-15T19:41:03.330845",
     "exception": false,
     "start_time": "2025-04-15T19:41:03.133813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086449ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:03.354455Z",
     "iopub.status.busy": "2025-04-15T19:41:03.354108Z",
     "iopub.status.idle": "2025-04-15T19:41:03.359780Z",
     "shell.execute_reply": "2025-04-15T19:41:03.358718Z"
    },
    "papermill": {
     "duration": 0.01907,
     "end_time": "2025-04-15T19:41:03.361136",
     "exception": false,
     "start_time": "2025-04-15T19:41:03.342066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI initialized for project capstone-project in us-central1.\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"capstone-project\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "try:\n",
    "    aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "    print(f\"Vertex AI initialized for project {PROJECT_ID} in {LOCATION}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Vertex AI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db61e3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:03.384561Z",
     "iopub.status.busy": "2025-04-15T19:41:03.384223Z",
     "iopub.status.idle": "2025-04-15T19:41:04.414938Z",
     "shell.execute_reply": "2025-04-15T19:41:04.413872Z"
    },
    "papermill": {
     "duration": 1.044449,
     "end_time": "2025-04-15T19:41:04.416492",
     "exception": false,
     "start_time": "2025-04-15T19:41:03.372043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 document chunks.\n",
      "Creating in-memory ChromaDB vector store and adding documents...\n",
      "ChromaDB retriever created.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ## 6. RAG Setup: Local Car Manual Embeddings & ChromaDB\n",
    "# ==============================================================================\n",
    "\n",
    "car_manual_text = \"\"\"\n",
    "## Headlights\n",
    "\n",
    "### Automatic Headlights\n",
    "Your vehicle is equipped with automatic headlights. To enable this feature, rotate the headlight switch stalk (usually on the left of the steering wheel) to the 'AUTO' position. The headlights will then turn on automatically in low light conditions or when wipers are activated.\n",
    "\n",
    "### Manual Headlight Operation\n",
    "To operate the headlights manually, rotate the switch stalk:\n",
    "- One click clockwise: Parking lights only.\n",
    "- Two clicks clockwise: Low beam headlights.\n",
    "- Pull the stalk towards you: High beam headlights (may flash or stay on depending on previous state). Push away to return to low beams.\n",
    "\n",
    "## Tire Pressure Monitoring System (TPMS)\n",
    "\n",
    "### Checking Tire Pressure\n",
    "Your vehicle's recommended tire pressure is listed on the sticker inside the driver's side doorjamb. For most models, it is typically 35 PSI when tires are cold. Use a reliable pressure gauge to check pressure regularly, ideally monthly.\n",
    "\n",
    "### TPMS Warning Light\n",
    "If the TPMS warning light (often looks like a tire cross-section with an exclamation mark) illuminates on your dashboard, it indicates one or more tires are significantly under-inflated. Check all tire pressures as soon as possible and inflate them to the recommended PSI. The light may take some driving to reset after inflation. If the light flashes, it usually indicates a system malfunction; consult your dealer.\n",
    "\n",
    "## Bluetooth Pairing\n",
    "\n",
    "### Pairing a New Device\n",
    "1. Ensure Bluetooth is enabled on your phone or audio device.\n",
    "2. On the vehicle's infotainment screen, navigate to Settings > Bluetooth > Add Device.\n",
    "3. The system will search for nearby devices. Select your device from the list.\n",
    "4. A pairing code may be displayed on both the screen and your device. Confirm they match.\n",
    "5. Accept the pairing request on your device.\n",
    "6. Once paired, you can select the device for audio playback or phone calls.\n",
    "\n",
    "### Troubleshooting Pairing\n",
    "If pairing fails, try turning Bluetooth off and on again on both the vehicle and your device. Ensure your device is discoverable. Delete old pairings if you have reached the maximum number of devices. Consult the infotainment system manual for more detailed steps.\n",
    "\n",
    "## Wipers\n",
    "\n",
    "### Front Wipers\n",
    "The wiper control stalk is typically on the right side of the steering column.\n",
    "- Push down once for a single wipe (mist).\n",
    "- Pull up one click for intermittent wipers. Rotate the band to adjust the delay.\n",
    "- Pull up two clicks for low speed continuous wipers.\n",
    "- Pull up three clicks for high speed continuous wipers.\n",
    "- Push the end button to spray washer fluid on the front windshield.\n",
    "\n",
    "### Rear Wiper (if equipped)\n",
    "Usually controlled by twisting the end cap of the right stalk.\n",
    "- Twist forward one position for intermittent rear wipe.\n",
    "- Twist forward two positions for continuous rear wipe.\n",
    "- Push the stalk away from you to spray rear washer fluid.\n",
    "\"\"\"\n",
    "\n",
    "vector_store = None\n",
    "retriever = None\n",
    "gemini_embeddings = None\n",
    "\n",
    "try:\n",
    "    gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        task_type=\"retrieval_document\"\n",
    "    )\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    doc_splits = [Document(page_content=chunk, metadata={\"source\": \"car_manual_local\"})\n",
    "                  for chunk in text_splitter.split_text(car_manual_text)]\n",
    "    print(f\"Created {len(doc_splits)} document chunks.\")\n",
    "\n",
    "    if doc_splits:\n",
    "        print(\"Creating in-memory ChromaDB vector store and adding documents...\")\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=doc_splits,\n",
    "            embedding=gemini_embeddings,\n",
    "\n",
    "        )\n",
    "\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        print(\"ChromaDB retriever created.\")\n",
    "    else:\n",
    "        print(\"No document splits generated, skipping vector store creation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during RAG setup: {e}\")\n",
    "    print(\"VehicleInfo tool might not function correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf41bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.441141Z",
     "iopub.status.busy": "2025-04-15T19:41:04.440838Z",
     "iopub.status.idle": "2025-04-15T19:41:04.455887Z",
     "shell.execute_reply": "2025-04-15T19:41:04.455087Z"
    },
    "papermill": {
     "duration": 0.028904,
     "end_time": "2025-04-15T19:41:04.457206",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.428302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = {\n",
    "    \"Home\": {\"type\": \"residence\", \"x\": 0, \"y\": 0},\n",
    "    \"Downtown Cafe\": {\"type\": \"coffee shop\", \"x\": 10, \"y\": 5},\n",
    "    \"Tech Park Cafe\": {\"type\": \"coffee shop\", \"x\": 45, \"y\": 35},\n",
    "    \"Main St Gas\": {\"type\": \"gas station\", \"x\": 12, \"y\": 0},\n",
    "    \"Highway Gas Stop\": {\"type\": \"gas station\", \"x\": 50, \"y\": 50},\n",
    "    \"Luigi's Pizza\": {\"type\": \"restaurant\", \"x\": 9, \"y\": 8},\n",
    "    \"Ocean Sushi\": {\"type\": \"restaurant\", \"x\": 25, \"y\": 18},\n",
    "    \"City Hall\": {\"type\": \"government\", \"x\": 20, \"y\": 20},\n",
    "    \"Shopping Mall\": {\"type\": \"shopping\", \"x\": 22, \"y\": 22},\n",
    "    \"Tech Park Work\": {\"type\": \"office\", \"x\": 40, \"y\": 30},\n",
    "    \"Park Entrance\": {\"type\": \"park\", \"x\": 18, \"y\": 25},\n",
    "    \"Library\": {\"type\": \"government\", \"x\": 19, \"y\": 19}\n",
    "}\n",
    "\n",
    "connections = {\n",
    "    \"Home\": {\"Main St Gas\": 12, \"Downtown Cafe\": 11, \"Luigi's Pizza\": 12},\n",
    "    \"Main St Gas\": {\"Home\": 12, \"Downtown Cafe\": 2, \"City Hall\": 10},\n",
    "    \"Downtown Cafe\": {\"Home\": 11, \"Main St Gas\": 2, \"Luigi's Pizza\": 1},\n",
    "    \"Luigi's Pizza\": {\"Downtown Cafe\": 1, \"Ocean Sushi\": 16, \"Library\": 13},\n",
    "    \"City Hall\": {\"Main St Gas\": 10, \"Library\": 1, \"Shopping Mall\": 2, \"Park Entrance\": 6, \"Ocean Sushi\": 7},\n",
    "    \"Library\": {\"Luigi's Pizza\": 13, \"City Hall\": 1},\n",
    "    \"Shopping Mall\": {\"City Hall\": 2, \"Park Entrance\": 3, \"Ocean Sushi\": 5},\n",
    "    \"Park Entrance\": {\"City Hall\": 6, \"Shopping Mall\": 3, \"Tech Park Work\": 15},\n",
    "    \"Ocean Sushi\": {\"Luigi's Pizza\": 16, \"City Hall\": 7, \"Shopping Mall\": 5, \"Tech Park Work\": 18},\n",
    "    \"Tech Park Work\": {\"Ocean Sushi\": 18, \"Park Entrance\": 15, \"Tech Park Cafe\": 5, \"Highway Gas Stop\": 12},\n",
    "    \"Tech Park Cafe\": {\"Tech Park Work\": 5, \"Highway Gas Stop\": 10},\n",
    "    \"Highway Gas Stop\": {\"Tech Park Cafe\": 10, \"Tech Park Work\": 12}\n",
    "}\n",
    "\n",
    "nodes_to_update = {}\n",
    "for node, neighbours in connections.items():\n",
    "    for neighbour, distance in neighbours.items():\n",
    "        if neighbour not in connections:\n",
    "             nodes_to_update[neighbour] = {}\n",
    "        if node not in connections.get(neighbour, {}):\n",
    "             if neighbour not in nodes_to_update: nodes_to_update[neighbour] = {}\n",
    "             nodes_to_update[neighbour][node] = distance\n",
    "connections.update(nodes_to_update)\n",
    "\n",
    "current_location_name = \"Home\"\n",
    "\n",
    "def find_shortest_path(graph, start, end):\n",
    "    \"\"\"Finds the shortest path between start and end nodes using Dijkstra.\"\"\"\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    previous_nodes = {node: None for node in graph}\n",
    "    priority_queue = [(0, start)]\n",
    "\n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        if current_node == end:\n",
    "            break\n",
    "\n",
    "        if current_node not in graph:\n",
    "             continue\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                previous_nodes[neighbor] = current_node\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "    path = []\n",
    "    current = end\n",
    "    if distances[current] == float('inf'):\n",
    "        return None, float('inf')\n",
    "\n",
    "    while current is not None:\n",
    "        path.append(current)\n",
    "        current = previous_nodes[current]\n",
    "    path.reverse()\n",
    "\n",
    "    return path, distances[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3d3aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.479703Z",
     "iopub.status.busy": "2025-04-15T19:41:04.479293Z",
     "iopub.status.idle": "2025-04-15T19:41:04.485325Z",
     "shell.execute_reply": "2025-04-15T19:41:04.484512Z"
    },
    "papermill": {
     "duration": 0.018959,
     "end_time": "2025-04-15T19:41:04.486733",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.467774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    current_request: str | None\n",
    "    last_agent_response: str | None\n",
    "    route_decision: Literal[\"Navigation\", \"Media\", \"Communication\", \"VehicleInfo\", \"Respond\", \"Error\", None]\n",
    "    vehicle_context: list[str] | None\n",
    "    navigation_context: dict | None\n",
    "    media_context: dict | None\n",
    "    communication_context: dict | None\n",
    "    error: str | None\n",
    "    final_response_generated: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e05e3e",
   "metadata": {
    "papermill": {
     "duration": 0.010354,
     "end_time": "2025-04-15T19:41:04.507811",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.497457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0ce221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.531026Z",
     "iopub.status.busy": "2025-04-15T19:41:04.530538Z",
     "iopub.status.idle": "2025-04-15T19:41:04.561918Z",
     "shell.execute_reply": "2025-04-15T19:41:04.560837Z"
    },
    "papermill": {
     "duration": 0.045388,
     "end_time": "2025-04-15T19:41:04.563701",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.518313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def navigation_tool(action: str, destination: str | None = None, poi_type: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Handles navigation tasks using a local graph map dataset.\n",
    "    Actions: 'find_poi', 'start_navigation', 'get_traffic'.\n",
    "    Requires 'poi_type' for 'find_poi' (e.g., 'coffee shop', 'gas station').\n",
    "    Requires 'destination' name (must match a key in the 'locations' dictionary) for 'start_navigation'.\n",
    "    'get_traffic' action is simplified.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: navigation_tool (Action: {action}, Destination: {destination}, POI: {poi_type}) ---\")\n",
    "    global current_location_name\n",
    "    global locations\n",
    "    global connections\n",
    "\n",
    "    current_loc_details = locations.get(current_location_name)\n",
    "    if not current_loc_details:\n",
    "        return \"Error: Current location unknown or invalid.\"\n",
    "    current_x = current_loc_details[\"x\"]\n",
    "    current_y = current_loc_details[\"y\"]\n",
    "\n",
    "    try:\n",
    "        if action == \"find_poi\":\n",
    "            if poi_type:\n",
    "                found_pois = []\n",
    "                poi_type_lower = poi_type.lower()\n",
    "                for name, details in locations.items():\n",
    "                    if details[\"type\"] == poi_type_lower:\n",
    "                        path, distance = find_shortest_path(connections, current_location_name, name)\n",
    "                        if path:\n",
    "                            found_pois.append({\"name\": name, \"distance\": distance, \"path\": path})\n",
    "\n",
    "                if not found_pois:\n",
    "                    return f\"Sorry, I couldn't find any reachable '{poi_type}' from {current_location_name} using the available roads.\"\n",
    "\n",
    "                found_pois.sort(key=lambda p: p[\"distance\"])\n",
    "                nearest_poi = found_pois[0]\n",
    "                return (f\"Found '{poi_type}': '{nearest_poi['name']}' is the closest reachable one \"\n",
    "                        f\"(distance: {nearest_poi['distance']:.1f} units via {', '.join(nearest_poi['path'])}).\")\n",
    "            else:\n",
    "                 return \"Error: Please specify a type of place (POI) to find (e.g., 'coffee shop').\"\n",
    "\n",
    "        elif action == \"start_navigation\":\n",
    "            if destination:\n",
    "                if destination == current_location_name:\n",
    "                    return f\"You are already at {destination}.\"\n",
    "\n",
    "                if destination in locations:\n",
    "                    path, distance = find_shortest_path(connections, current_location_name, destination)\n",
    "                    if path:\n",
    "                        current_location_name = destination\n",
    "                        print(f\"   INFO: Simulating navigation. Current location updated to {destination}\")\n",
    "                        first_step = path[1] if len(path) > 1 else destination\n",
    "                        return (f\"Starting navigation to {destination}. \"\n",
    "                                f\"Estimated travel distance: {distance:.1f} units. \"\n",
    "                                f\"Route: {', '.join(path)}. First head towards {first_step}.\")\n",
    "                    else:\n",
    "                        return f\"Sorry, I couldn't find a route in the local map data from {current_location_name} to {destination}.\"\n",
    "                else:\n",
    "                    return f\"Sorry, I don't have '{destination}' in my local map data.\"\n",
    "            else:\n",
    "                 return \"Error: Please specify a destination for navigation.\"\n",
    "\n",
    "        elif action == \"get_traffic\":\n",
    "             if destination:\n",
    "                 if destination in locations:\n",
    "                      path, distance = find_shortest_path(connections, current_location_name, destination)\n",
    "                      if distance > 20:\n",
    "                          return f\"Simulated: Traffic towards {destination} looks heavy based on distance.\"\n",
    "                      else:\n",
    "                          return f\"Simulated: Traffic towards {destination} looks moderate.\"\n",
    "                 else:\n",
    "                     return f\"Cannot check traffic for unknown destination: {destination}\"\n",
    "             else:\n",
    "                 return \"Simulated: Traffic in the current area appears moderate.\"\n",
    "\n",
    "        else:\n",
    "            return f\"Error: Invalid navigation action '{action}'. Use 'find_poi', 'start_navigation', or 'get_traffic'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR during local navigation tool execution: {e}\")\n",
    "        return f\"Sorry, I encountered an internal error using the local navigation tool.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def media_tool(action: str, query: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Simulates interaction with a Media API.\n",
    "    Actions can be 'play', 'pause', 'search_music', 'search_podcast'.\n",
    "    Requires query for search actions.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: media_tool (Action: {action}, Query: {query}) ---\")\n",
    "    if action == \"play\" and query:\n",
    "        return f\"Simulated: Playing '{query}'.\"\n",
    "    elif action == \"play\":\n",
    "        return f\"Simulated: Resuming playback.\"\n",
    "    elif action == \"pause\":\n",
    "        return \"Simulated: Pausing media.\"\n",
    "    elif action == \"search_music\" and query:\n",
    "        return f\"Simulated: Found music matching '{query}'.\"\n",
    "    elif action == \"search_podcast\" and query:\n",
    "         return f\"Simulated: Found podcasts matching '{query}'.\"\n",
    "    else:\n",
    "        return \"Simulated: Invalid media action or missing query.\"\n",
    "\n",
    "@tool\n",
    "def communication_tool(action: str, recipient: str | None = None, message: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Simulates interaction with a Communication API (e.g., SMS, Email).\n",
    "    Actions can be 'send_message', 'read_last_message'.\n",
    "    Requires recipient and message for 'send_message'.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: communication_tool (Action: {action}, Recipient: {recipient}) ---\")\n",
    "    if action == \"send_message\" and recipient and message:\n",
    "        return f\"Simulated: Sending message '{message}' to {recipient}.\"\n",
    "    elif action == \"read_last_message\":\n",
    "        return \"Simulated: Last message reads 'On my way!'\"\n",
    "    else:\n",
    "        return \"Simulated: Invalid communication action or missing parameters.\"\n",
    "\n",
    "@tool\n",
    "def get_vehicle_info(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Provides information about the vehicle's features and functions by\n",
    "    searching the local car manual vector store using RAG. Use this for\n",
    "    questions about how to operate the car or troubleshoot issues.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: get_vehicle_info (Query: {query}) ---\")\n",
    "    global retriever\n",
    "\n",
    "    if not retriever:\n",
    "        print(\"   ERROR: Local vector store retriever is not available.\")\n",
    "        if \"headlight\" in query.lower():\n",
    "            return \"Simulated Fallback: To turn on the headlights, rotate the dial on the left stalk clockwise.\"\n",
    "        elif \"tire pressure\" in query.lower():\n",
    "             return \"Simulated Fallback: Recommended tire pressure is 35 PSI for all tires.\"\n",
    "        else:\n",
    "            return \"Error: The vehicle information system (manual search) is currently unavailable.\"\n",
    "\n",
    "    try:\n",
    "        print(f\"   Searching local vector store for: '{query}'\")\n",
    "\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "\n",
    "        if not relevant_docs:\n",
    "             print(\"   No relevant documents found in local store.\")\n",
    "             return \"I looked through the manual, but couldn't find specific information for that query.\"\n",
    "\n",
    "        context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        print(f\"   Found {len(relevant_docs)} relevant chunks.\")\n",
    "        return f\"Retrieved Context from Local Manual:\\n{context}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR during local vector store search: {e}\")\n",
    "        return f\"Sorry, I encountered an technical error while searching the vehicle manual: {e}. Please try rephrasing your question.\"\n",
    "\n",
    "available_tools = [navigation_tool, media_tool, communication_tool, get_vehicle_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1bc165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.586943Z",
     "iopub.status.busy": "2025-04-15T19:41:04.586559Z",
     "iopub.status.idle": "2025-04-15T19:41:04.611232Z",
     "shell.execute_reply": "2025-04-15T19:41:04.609869Z"
    },
    "papermill": {
     "duration": 0.038743,
     "end_time": "2025-04-15T19:41:04.613110",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.574367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 'models/gemini-2.0-flash' initialized with tools.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(available_tools)\n",
    "\n",
    "print(f\"LLM '{llm.model}' initialized with tools.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1cf748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.638234Z",
     "iopub.status.busy": "2025-04-15T19:41:04.637855Z",
     "iopub.status.idle": "2025-04-15T19:41:04.653478Z",
     "shell.execute_reply": "2025-04-15T19:41:04.652597Z"
    },
    "papermill": {
     "duration": 0.029903,
     "end_time": "2025-04-15T19:41:04.654878",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.624975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def voice_interface_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Simulates capturing user voice input and performing STT/NLU.\"\"\"\n",
    "    print(\"--- NODE: Voice Interface ---\")\n",
    "    user_input = input(\"User Input: \")\n",
    "    if user_input.lower() in ['q', 'quit', 'exit']:\n",
    "         return {\"messages\": [HumanMessage(content=user_input)], \"final_response_generated\": True, \"route_decision\": None}\n",
    "\n",
    "    return {\"messages\": [HumanMessage(content=user_input)], \"current_request\": user_input, \"final_response_generated\": False}\n",
    "\n",
    "\n",
    "def orchestrator_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Uses the LLM to decide the next step: call a tool, respond directly, or flag an error.\n",
    "    The LLM's response might contain tool calls.\n",
    "    \"\"\"\n",
    "    print(\"--- NODE: Orchestrator (LLM Based) ---\")\n",
    "    messages = state['messages']\n",
    "    llm_response = llm_with_tools.invoke([\n",
    "        AIMessage(content=\"You are the central orchestrator for an automotive AI assistant. Your goal is to understand the user's request and decide the next step. You can either call one of the available tools (Navigation, Media, Communication, VehicleInfo) if needed to fulfill the request, or if you have enough information or the request is conversational, generate a direct response for the user. If a tool is needed, respond *only* with the appropriate tool call. If a direct response is appropriate, provide that response.\"),\n",
    "        *messages\n",
    "    ])\n",
    "\n",
    "    print(f\"   Orchestrator LLM Response: {type(llm_response)}\")\n",
    "    if hasattr(llm_response, 'tool_calls') and llm_response.tool_calls:\n",
    "        print(f\"   Tool Calls Planned: {[tc['name'] for tc in llm_response.tool_calls]}\")\n",
    "    else:\n",
    "        print(f\"   Direct Response Planned: {llm_response.content[:100]}...\")\n",
    "\n",
    "    return {\"messages\": [llm_response]}\n",
    "\n",
    "navigation_node = ToolNode([navigation_tool])\n",
    "media_node = ToolNode([media_tool])\n",
    "communication_node = ToolNode([communication_tool])\n",
    "vehicle_info_node = ToolNode([get_vehicle_info])\n",
    "\n",
    "def response_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generates the final response to the user based on gathered context from tools OR direct LLM call.\"\"\"\n",
    "    print(\"--- NODE: Response Agent ---\")\n",
    "    user_request = state.get('current_request', 'the user request')\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "    context_from_tool = None\n",
    "\n",
    "    if isinstance(last_message, ToolMessage):\n",
    "         print(f\"   Using context from tool: {last_message.name}\")\n",
    "         context_from_tool = last_message.content\n",
    "         original_user_request = user_request\n",
    "         tool_call_idx = -1\n",
    "         for i in range(len(messages) - 2, -1, -1):\n",
    "              if isinstance(messages[i], AIMessage) and messages[i].tool_calls:\n",
    "                   tool_call_idx = i\n",
    "              if isinstance(messages[i], HumanMessage) and tool_call_idx != -1:\n",
    "                   original_user_request = messages[i].content\n",
    "                   print(f\"   Found originating user request: '{original_user_request}'\")\n",
    "                   break\n",
    "         prompt_question = original_user_request\n",
    "    else:\n",
    "         if isinstance(last_message, AIMessage):\n",
    "              context_from_tool = last_message.content\n",
    "         prompt_question = user_request\n",
    "\n",
    "\n",
    "    prompt = f\"You are an automotive assistant. The user asked: '{prompt_question}'. \"\n",
    "    if context_from_tool:\n",
    "        if \"error\" in context_from_tool.lower() and \"tool call\" in context_from_tool.lower():\n",
    "             prompt += f\"A tool call failed with: '{context_from_tool}'. Apologize and ask the user to rephrase or try again.\"\n",
    "        elif \"error\" in context_from_tool.lower() and \"local vector store\" in context_from_tool.lower():\n",
    "             prompt += f\"A tool call failed with: '{context_from_tool}'. Apologize and ask the user to rephrase or try again.\"\n",
    "        elif \"information not found\" in context_from_tool.lower():\n",
    "             prompt += \"Based on the manual, the specific information requested wasn't found. State this clearly.\"\n",
    "        else:\n",
    "             prompt += f\"Using the following information retrieved from the vehicle manual: '{context_from_tool}'. Formulate a helpful and concise answer based *only* on this retrieved context.\"\n",
    "    else:\n",
    "        print(\"   No tool context found, generating response based on conversation history.\")\n",
    "\n",
    "        final_response = llm.invoke(messages)\n",
    "        print(f\"   Generated direct response: {final_response.content[:100]}...\")\n",
    "        return {\"messages\": [final_response], \"final_response_generated\": True}\n",
    "\n",
    "    final_response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    print(f\"   Generated response based on context: {final_response.content[:100]}...\")\n",
    "    return {\"messages\": [final_response], \"final_response_generated\": True}\n",
    "\n",
    "def error_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles errors and informs the user.\"\"\"\n",
    "    print(\"--- NODE: Error Handler ---\")\n",
    "    error_message = state.get('error', 'An unknown error occurred.')\n",
    "    response = AIMessage(content=f\"Sorry, I encountered an error: {error_message}. Please try again.\")\n",
    "    return {\"messages\": [response], \"final_response_generated\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b74e3",
   "metadata": {
    "papermill": {
     "duration": 0.010309,
     "end_time": "2025-04-15T19:41:04.676291",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.665982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Graph Edges and Conditional Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e62b7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.698883Z",
     "iopub.status.busy": "2025-04-15T19:41:04.698523Z",
     "iopub.status.idle": "2025-04-15T19:41:04.705637Z",
     "shell.execute_reply": "2025-04-15T19:41:04.704838Z"
    },
    "papermill": {
     "duration": 0.020424,
     "end_time": "2025-04-15T19:41:04.707208",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.686784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_route(state: AgentState) -> Literal[\"ExecuteTool\", \"Respond\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Determines the next node based on the LAST message in the state.\n",
    "    Routes to ExecuteTool if the last message has tool calls,\n",
    "    otherwise routes to Respond to output the message, or ENDs if finished.\n",
    "    \"\"\"\n",
    "    print(\"--- ROUTING ---\")\n",
    "    if state.get(\"final_response_generated\", False):\n",
    "         print(\"   Decision: End of interaction signaled.\")\n",
    "         return END\n",
    "\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "\n",
    "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        print(f\"   Decision: Route to ExecuteTool for calls: {[tc['name'] for tc in last_message.tool_calls]}\")\n",
    "        return \"ExecuteTool\"\n",
    "    elif isinstance(last_message, AIMessage):\n",
    "         print(\"   Decision: Route to END (AI message is final response)\")\n",
    "         return END\n",
    "    elif isinstance(last_message, HumanMessage) and last_message.content.lower().strip() in ['q', 'quit', 'exit', 'goodbye', 'stop']:\n",
    "         print(\"   Decision: End of interaction requested by user.\")\n",
    "         return END\n",
    "    else:\n",
    "         print(\"Fallback\")\n",
    "         return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccb129",
   "metadata": {
    "papermill": {
     "duration": 0.010192,
     "end_time": "2025-04-15T19:41:04.727868",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.717676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189d2aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:04.750523Z",
     "iopub.status.busy": "2025-04-15T19:41:04.750168Z",
     "iopub.status.idle": "2025-04-15T19:41:14.825686Z",
     "shell.execute_reply": "2025-04-15T19:41:14.824797Z"
    },
    "papermill": {
     "duration": 10.088906,
     "end_time": "2025-04-15T19:41:14.827169",
     "exception": false,
     "start_time": "2025-04-15T19:41:04.738263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph rebuilt successfully for RAG flow.\n",
      "Could not display graph visualization: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\n"
     ]
    }
   ],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"UserInput\", voice_interface_agent)\n",
    "graph_builder.add_node(\"Orchestrator\", orchestrator_agent)\n",
    "\n",
    "tool_executor_node = ToolNode(available_tools)\n",
    "graph_builder.add_node(\"ExecuteTool\", tool_executor_node)\n",
    "\n",
    "graph_builder.add_node(\"Error\", error_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"UserInput\")\n",
    "graph_builder.add_edge(\"UserInput\", \"Orchestrator\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Orchestrator\",\n",
    "    select_route,\n",
    "    {\n",
    "        \"ExecuteTool\": \"ExecuteTool\",\n",
    "        \"Error\": \"Error\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"ExecuteTool\", \"Orchestrator\")\n",
    "graph_builder.add_edge(\"Error\", END)\n",
    "app_graph = graph_builder.compile()\n",
    "\n",
    "print(\"Graph rebuilt successfully for RAG flow.\")\n",
    "\n",
    "try:\n",
    "    display(Image(app_graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"Graph visualization displayed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdec66",
   "metadata": {
    "papermill": {
     "duration": 0.010609,
     "end_time": "2025-04-15T19:41:14.848732",
     "exception": false,
     "start_time": "2025-04-15T19:41:14.838123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run the Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4d1da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T19:41:14.871052Z",
     "iopub.status.busy": "2025-04-15T19:41:14.870745Z",
     "iopub.status.idle": "2025-04-15T19:41:14.879414Z",
     "shell.execute_reply": "2025-04-15T19:41:14.878463Z"
    },
    "papermill": {
     "duration": 0.021442,
     "end_time": "2025-04-15T19:41:14.880794",
     "exception": false,
     "start_time": "2025-04-15T19:41:14.859352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NODE: Voice Interface ---\n",
      "\n",
      "An error occurred during execution: raw_input was called, but this frontend does not support input requests.\n"
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 15}\n",
    "\n",
    "initial_state = {\"messages\": [], \"final_response_generated\": False}\n",
    "\n",
    "try:\n",
    "    final_state = app_graph.invoke(initial_state, config=config)\n",
    "    print(\"\\n--- Interaction Ended ---\")\n",
    "    print(\"\\nFinal State:\")\n",
    "    pprint(final_state)\n",
    "except Exception as e:\n",
    "     print(f\"\\nAn error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84fb3f",
   "metadata": {
    "papermill": {
     "duration": 0.011017,
     "end_time": "2025-04-15T19:41:14.903167",
     "exception": false,
     "start_time": "2025-04-15T19:41:14.892150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.209345,
   "end_time": "2025-04-15T19:41:18.349107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-15T19:39:15.139762",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
