{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad01a65",
   "metadata": {
    "papermill": {
     "duration": 0.004418,
     "end_time": "2025-04-14T15:02:24.133924",
     "exception": false,
     "start_time": "2025-04-14T15:02:24.129506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Autonomous Multi-Agent System for Enhanced Automotive User Experience\n",
    "\n",
    "#### Capstone Project - Kaggle 5-Day Generative AI Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b0f771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:02:24.142855Z",
     "iopub.status.busy": "2025-04-14T15:02:24.142435Z",
     "iopub.status.idle": "2025-04-14T15:03:13.627999Z",
     "shell.execute_reply": "2025-04-14T15:03:13.626961Z"
    },
    "papermill": {
     "duration": 49.492318,
     "end_time": "2025-04-14T15:03:13.630007",
     "exception": false,
     "start_time": "2025-04-14T15:02:24.137689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy kfp jupyterlab google-generativeai tensorflow-hub 2>/dev/null\n",
    "!pip install -U -q langchain langchain-google-genai langgraph google-cloud-aiplatform pandas scikit-learn \"langchain-community>=0.2.7\" \"langchain-core>=0.2.19\"\n",
    "!pip install -U -q google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785aeaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:13.641769Z",
     "iopub.status.busy": "2025-04-14T15:03:13.641098Z",
     "iopub.status.idle": "2025-04-14T15:03:28.366210Z",
     "shell.execute_reply": "2025-04-14T15:03:28.365492Z"
    },
    "papermill": {
     "duration": 14.732887,
     "end_time": "2025-04-14T15:03:28.367783",
     "exception": false,
     "start_time": "2025-04-14T15:03:13.634896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "import uuid\n",
    "import math\n",
    "import heapq\n",
    "from collections.abc import Iterable\n",
    "from random import randint\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "from langchain_community.vectorstores.matching_engine import MatchingEngine\n",
    "\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5e5559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.378504Z",
     "iopub.status.busy": "2025-04-14T15:03:28.377525Z",
     "iopub.status.idle": "2025-04-14T15:03:28.582396Z",
     "shell.execute_reply": "2025-04-14T15:03:28.581616Z"
    },
    "papermill": {
     "duration": 0.21172,
     "end_time": "2025-04-14T15:03:28.584074",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.372354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda88434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.601076Z",
     "iopub.status.busy": "2025-04-14T15:03:28.600132Z",
     "iopub.status.idle": "2025-04-14T15:03:28.606204Z",
     "shell.execute_reply": "2025-04-14T15:03:28.605322Z"
    },
    "papermill": {
     "duration": 0.01354,
     "end_time": "2025-04-14T15:03:28.607412",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.593872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI initialized for project capstone-project in us-central1.\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"capstone-project\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "try:\n",
    "    aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "    print(f\"Vertex AI initialized for project {PROJECT_ID} in {LOCATION}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Vertex AI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3030e25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.620051Z",
     "iopub.status.busy": "2025-04-14T15:03:28.619581Z",
     "iopub.status.idle": "2025-04-14T15:03:28.634838Z",
     "shell.execute_reply": "2025-04-14T15:03:28.633911Z"
    },
    "papermill": {
     "duration": 0.022728,
     "end_time": "2025-04-14T15:03:28.636234",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.613506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = {\n",
    "    \"Home\": {\"type\": \"residence\", \"x\": 0, \"y\": 0},\n",
    "    \"Downtown Cafe\": {\"type\": \"coffee shop\", \"x\": 10, \"y\": 5},\n",
    "    \"Tech Park Cafe\": {\"type\": \"coffee shop\", \"x\": 45, \"y\": 35},\n",
    "    \"Main St Gas\": {\"type\": \"gas station\", \"x\": 12, \"y\": 0},\n",
    "    \"Highway Gas Stop\": {\"type\": \"gas station\", \"x\": 50, \"y\": 50},\n",
    "    \"Luigi's Pizza\": {\"type\": \"restaurant\", \"x\": 9, \"y\": 8},\n",
    "    \"Ocean Sushi\": {\"type\": \"restaurant\", \"x\": 25, \"y\": 18},\n",
    "    \"City Hall\": {\"type\": \"government\", \"x\": 20, \"y\": 20},\n",
    "    \"Shopping Mall\": {\"type\": \"shopping\", \"x\": 22, \"y\": 22},\n",
    "    \"Tech Park Work\": {\"type\": \"office\", \"x\": 40, \"y\": 30},\n",
    "    \"Park Entrance\": {\"type\": \"park\", \"x\": 18, \"y\": 25},\n",
    "    \"Library\": {\"type\": \"government\", \"x\": 19, \"y\": 19}\n",
    "}\n",
    "\n",
    "connections = {\n",
    "    \"Home\": {\"Main St Gas\": 12, \"Downtown Cafe\": 11, \"Luigi's Pizza\": 12},\n",
    "    \"Main St Gas\": {\"Home\": 12, \"Downtown Cafe\": 2, \"City Hall\": 10},\n",
    "    \"Downtown Cafe\": {\"Home\": 11, \"Main St Gas\": 2, \"Luigi's Pizza\": 1},\n",
    "    \"Luigi's Pizza\": {\"Downtown Cafe\": 1, \"Ocean Sushi\": 16, \"Library\": 13},\n",
    "    \"City Hall\": {\"Main St Gas\": 10, \"Library\": 1, \"Shopping Mall\": 2, \"Park Entrance\": 6, \"Ocean Sushi\": 7},\n",
    "    \"Library\": {\"Luigi's Pizza\": 13, \"City Hall\": 1},\n",
    "    \"Shopping Mall\": {\"City Hall\": 2, \"Park Entrance\": 3, \"Ocean Sushi\": 5},\n",
    "    \"Park Entrance\": {\"City Hall\": 6, \"Shopping Mall\": 3, \"Tech Park Work\": 15},\n",
    "    \"Ocean Sushi\": {\"Luigi's Pizza\": 16, \"City Hall\": 7, \"Shopping Mall\": 5, \"Tech Park Work\": 18},\n",
    "    \"Tech Park Work\": {\"Ocean Sushi\": 18, \"Park Entrance\": 15, \"Tech Park Cafe\": 5, \"Highway Gas Stop\": 12},\n",
    "    \"Tech Park Cafe\": {\"Tech Park Work\": 5, \"Highway Gas Stop\": 10},\n",
    "    \"Highway Gas Stop\": {\"Tech Park Cafe\": 10, \"Tech Park Work\": 12}\n",
    "}\n",
    "\n",
    "nodes_to_update = {}\n",
    "for node, neighbours in connections.items():\n",
    "    for neighbour, distance in neighbours.items():\n",
    "        if neighbour not in connections:\n",
    "             nodes_to_update[neighbour] = {}\n",
    "        if node not in connections.get(neighbour, {}):\n",
    "             if neighbour not in nodes_to_update: nodes_to_update[neighbour] = {}\n",
    "             nodes_to_update[neighbour][node] = distance\n",
    "connections.update(nodes_to_update)\n",
    "\n",
    "current_location_name = \"Home\"\n",
    "\n",
    "def find_shortest_path(graph, start, end):\n",
    "    \"\"\"Finds the shortest path between start and end nodes using Dijkstra.\"\"\"\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    previous_nodes = {node: None for node in graph}\n",
    "    priority_queue = [(0, start)]\n",
    "\n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        if current_node == end:\n",
    "            break\n",
    "\n",
    "        if current_node not in graph:\n",
    "             continue\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                previous_nodes[neighbor] = current_node\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "    path = []\n",
    "    current = end\n",
    "    if distances[current] == float('inf'):\n",
    "        return None, float('inf')\n",
    "\n",
    "    while current is not None:\n",
    "        path.append(current)\n",
    "        current = previous_nodes[current]\n",
    "    path.reverse()\n",
    "\n",
    "    return path, distances[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b69e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.646723Z",
     "iopub.status.busy": "2025-04-14T15:03:28.646420Z",
     "iopub.status.idle": "2025-04-14T15:03:28.653033Z",
     "shell.execute_reply": "2025-04-14T15:03:28.652194Z"
    },
    "papermill": {
     "duration": 0.013317,
     "end_time": "2025-04-14T15:03:28.654367",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.641050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    current_request: str | None\n",
    "    last_agent_response: str | None\n",
    "    route_decision: Literal[\"Navigation\", \"Media\", \"Communication\", \"VehicleInfo\", \"Respond\", \"Error\", None]\n",
    "    vehicle_context: list[str] | None\n",
    "    navigation_context: dict | None\n",
    "    media_context: dict | None\n",
    "    communication_context: dict | None\n",
    "    error: str | None\n",
    "    final_response_generated: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47373ec",
   "metadata": {
    "papermill": {
     "duration": 0.004163,
     "end_time": "2025-04-14T15:03:28.663650",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.659487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd24ba61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.674970Z",
     "iopub.status.busy": "2025-04-14T15:03:28.674631Z",
     "iopub.status.idle": "2025-04-14T15:03:28.702708Z",
     "shell.execute_reply": "2025-04-14T15:03:28.701746Z"
    },
    "papermill": {
     "duration": 0.037171,
     "end_time": "2025-04-14T15:03:28.705308",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.668137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def navigation_tool(action: str, destination: str | None = None, poi_type: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Handles navigation tasks using a local graph map dataset.\n",
    "    Actions: 'find_poi', 'start_navigation', 'get_traffic'.\n",
    "    Requires 'poi_type' for 'find_poi' (e.g., 'coffee shop', 'gas station').\n",
    "    Requires 'destination' name (must match a key in the 'locations' dictionary) for 'start_navigation'.\n",
    "    'get_traffic' action is simplified.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: navigation_tool (Action: {action}, Destination: {destination}, POI: {poi_type}) ---\")\n",
    "    global current_location_name\n",
    "    global locations\n",
    "    global connections\n",
    "\n",
    "    current_loc_details = locations.get(current_location_name)\n",
    "    if not current_loc_details:\n",
    "        return \"Error: Current location unknown or invalid.\"\n",
    "    current_x = current_loc_details[\"x\"]\n",
    "    current_y = current_loc_details[\"y\"]\n",
    "\n",
    "    try:\n",
    "        if action == \"find_poi\":\n",
    "            if poi_type:\n",
    "                found_pois = []\n",
    "                poi_type_lower = poi_type.lower()\n",
    "                for name, details in locations.items():\n",
    "                    if details[\"type\"] == poi_type_lower:\n",
    "                        path, distance = find_shortest_path(connections, current_location_name, name)\n",
    "                        if path:\n",
    "                            found_pois.append({\"name\": name, \"distance\": distance, \"path\": path})\n",
    "\n",
    "                if not found_pois:\n",
    "                    return f\"Sorry, I couldn't find any reachable '{poi_type}' from {current_location_name} using the available roads.\"\n",
    "\n",
    "                found_pois.sort(key=lambda p: p[\"distance\"])\n",
    "                nearest_poi = found_pois[0]\n",
    "                return (f\"Found '{poi_type}': '{nearest_poi['name']}' is the closest reachable one \"\n",
    "                        f\"(distance: {nearest_poi['distance']:.1f} units via {', '.join(nearest_poi['path'])}).\")\n",
    "            else:\n",
    "                 return \"Error: Please specify a type of place (POI) to find (e.g., 'coffee shop').\"\n",
    "\n",
    "        elif action == \"start_navigation\":\n",
    "            if destination:\n",
    "                if destination == current_location_name:\n",
    "                    return f\"You are already at {destination}.\"\n",
    "\n",
    "                if destination in locations:\n",
    "                    path, distance = find_shortest_path(connections, current_location_name, destination)\n",
    "                    if path:\n",
    "                        current_location_name = destination\n",
    "                        print(f\"   INFO: Simulating navigation. Current location updated to {destination}\")\n",
    "                        first_step = path[1] if len(path) > 1 else destination\n",
    "                        return (f\"Starting navigation to {destination}. \"\n",
    "                                f\"Estimated travel distance: {distance:.1f} units. \"\n",
    "                                f\"Route: {', '.join(path)}. First head towards {first_step}.\")\n",
    "                    else:\n",
    "                        return f\"Sorry, I couldn't find a route in the local map data from {current_location_name} to {destination}.\"\n",
    "                else:\n",
    "                    return f\"Sorry, I don't have '{destination}' in my local map data.\"\n",
    "            else:\n",
    "                 return \"Error: Please specify a destination for navigation.\"\n",
    "\n",
    "        elif action == \"get_traffic\":\n",
    "             if destination:\n",
    "                 if destination in locations:\n",
    "                      path, distance = find_shortest_path(connections, current_location_name, destination)\n",
    "                      if distance > 20:\n",
    "                          return f\"Simulated: Traffic towards {destination} looks heavy based on distance.\"\n",
    "                      else:\n",
    "                          return f\"Simulated: Traffic towards {destination} looks moderate.\"\n",
    "                 else:\n",
    "                     return f\"Cannot check traffic for unknown destination: {destination}\"\n",
    "             else:\n",
    "                 return \"Simulated: Traffic in the current area appears moderate.\"\n",
    "\n",
    "        else:\n",
    "            return f\"Error: Invalid navigation action '{action}'. Use 'find_poi', 'start_navigation', or 'get_traffic'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR during local navigation tool execution: {e}\")\n",
    "        return f\"Sorry, I encountered an internal error using the local navigation tool.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def media_tool(action: str, query: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Simulates interaction with a Media API.\n",
    "    Actions can be 'play', 'pause', 'search_music', 'search_podcast'.\n",
    "    Requires query for search actions.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: media_tool (Action: {action}, Query: {query}) ---\")\n",
    "    if action == \"play\" and query:\n",
    "        return f\"Simulated: Playing '{query}'.\"\n",
    "    elif action == \"play\":\n",
    "        return f\"Simulated: Resuming playback.\"\n",
    "    elif action == \"pause\":\n",
    "        return \"Simulated: Pausing media.\"\n",
    "    elif action == \"search_music\" and query:\n",
    "        return f\"Simulated: Found music matching '{query}'.\"\n",
    "    elif action == \"search_podcast\" and query:\n",
    "         return f\"Simulated: Found podcasts matching '{query}'.\"\n",
    "    else:\n",
    "        return \"Simulated: Invalid media action or missing query.\"\n",
    "\n",
    "@tool\n",
    "def communication_tool(action: str, recipient: str | None = None, message: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Simulates interaction with a Communication API (e.g., SMS, Email).\n",
    "    Actions can be 'send_message', 'read_last_message'.\n",
    "    Requires recipient and message for 'send_message'.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: communication_tool (Action: {action}, Recipient: {recipient}) ---\")\n",
    "    if action == \"send_message\" and recipient and message:\n",
    "        return f\"Simulated: Sending message '{message}' to {recipient}.\"\n",
    "    elif action == \"read_last_message\":\n",
    "        return \"Simulated: Last message reads 'On my way!'\"\n",
    "    else:\n",
    "        return \"Simulated: Invalid communication action or missing parameters.\"\n",
    "\n",
    "@tool\n",
    "def get_vehicle_info(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Provides information about the vehicle's features and functions by\n",
    "    searching the car manual. Use this for questions about how to operate\n",
    "    the car or troubleshoot issues.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL CALL: get_vehicle_info (Query: {query}) ---\")\n",
    "    if \"headlight\" in query.lower():\n",
    "        return \"Simulated RAG: To turn on the headlights, rotate the dial on the left stalk clockwise.\"\n",
    "    elif \"tire pressure\" in query.lower():\n",
    "         return \"Simulated RAG: Recommended tire pressure is 35 PSI for all tires.\"\n",
    "    else:\n",
    "        return \"Simulated RAG: Information not found in the manual for that query.\"\n",
    "\n",
    "available_tools = [navigation_tool, media_tool, communication_tool, get_vehicle_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febfdb0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.715597Z",
     "iopub.status.busy": "2025-04-14T15:03:28.715286Z",
     "iopub.status.idle": "2025-04-14T15:03:28.800927Z",
     "shell.execute_reply": "2025-04-14T15:03:28.799827Z"
    },
    "papermill": {
     "duration": 0.092237,
     "end_time": "2025-04-14T15:03:28.802337",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.710100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 'models/gemini-2.0-flash' initialized with tools.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(available_tools)\n",
    "\n",
    "print(f\"LLM '{llm.model}' initialized with tools.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cbfe61d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.812691Z",
     "iopub.status.busy": "2025-04-14T15:03:28.812441Z",
     "iopub.status.idle": "2025-04-14T15:03:28.822490Z",
     "shell.execute_reply": "2025-04-14T15:03:28.821785Z"
    },
    "papermill": {
     "duration": 0.016936,
     "end_time": "2025-04-14T15:03:28.823940",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.807004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def voice_interface_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Simulates capturing user voice input and performing STT/NLU.\"\"\"\n",
    "    print(\"--- NODE: Voice Interface ---\")\n",
    "    user_input = input(\"User Input: \")\n",
    "    if user_input.lower() in ['q', 'quit', 'exit']:\n",
    "         return {\"messages\": [HumanMessage(content=user_input)], \"final_response_generated\": True, \"route_decision\": None}\n",
    "\n",
    "    return {\"messages\": [HumanMessage(content=user_input)], \"current_request\": user_input, \"final_response_generated\": False}\n",
    "\n",
    "\n",
    "def orchestrator_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Uses the LLM to decide the next step: call a tool, respond directly, or flag an error.\n",
    "    The LLM's response might contain tool calls.\n",
    "    \"\"\"\n",
    "    print(\"--- NODE: Orchestrator (LLM Based) ---\")\n",
    "    messages = state['messages']\n",
    "    llm_response = llm_with_tools.invoke([\n",
    "        AIMessage(content=\"You are the central orchestrator for an automotive AI assistant. Your goal is to understand the user's request and decide the next step. You can either call one of the available tools (Navigation, Media, Communication, VehicleInfo) if needed to fulfill the request, or if you have enough information or the request is conversational, generate a direct response for the user. If a tool is needed, respond *only* with the appropriate tool call. If a direct response is appropriate, provide that response.\"),\n",
    "        *messages\n",
    "    ])\n",
    "\n",
    "    print(f\"   Orchestrator LLM Response: {type(llm_response)}\")\n",
    "    if hasattr(llm_response, 'tool_calls') and llm_response.tool_calls:\n",
    "        print(f\"   Tool Calls Planned: {[tc['name'] for tc in llm_response.tool_calls]}\")\n",
    "    else:\n",
    "        print(f\"   Direct Response Planned: {llm_response.content[:100]}...\")\n",
    "\n",
    "    return {\"messages\": [llm_response]}\n",
    "\n",
    "navigation_node = ToolNode([navigation_tool])\n",
    "media_node = ToolNode([media_tool])\n",
    "communication_node = ToolNode([communication_tool])\n",
    "vehicle_info_node = ToolNode([get_vehicle_info])\n",
    "\n",
    "def response_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generates the final response to the user based on gathered context.\"\"\"\n",
    "    print(\"--- NODE: Response Agent ---\")\n",
    "    user_request = state.get('current_request', 'the user request')\n",
    "    context = state.get('last_agent_response', None)\n",
    "\n",
    "    prompt = f\"You are an automotive assistant. The user asked: '{user_request}'. \"\n",
    "    if context:\n",
    "        prompt += f\"Based on the following information: '{context}'. Formulate a helpful and concise response.\"\n",
    "    else:\n",
    "        prompt += \"Formulate a helpful and concise response. If you cannot fulfill the request based on the conversation history, politely say so.\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    print(f\"   Generated response: {response.content[:100]}...\")\n",
    "    \n",
    "    return {\"messages\": [response], \"final_response_generated\": True}\n",
    "\n",
    "def error_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handles errors and informs the user.\"\"\"\n",
    "    print(\"--- NODE: Error Handler ---\")\n",
    "    error_message = state.get('error', 'An unknown error occurred.')\n",
    "    response = AIMessage(content=f\"Sorry, I encountered an error: {error_message}. Please try again.\")\n",
    "    return {\"messages\": [response], \"final_response_generated\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffa013",
   "metadata": {
    "papermill": {
     "duration": 0.004332,
     "end_time": "2025-04-14T15:03:28.832956",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.828624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Graph Edges and Conditional Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8538df51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.843061Z",
     "iopub.status.busy": "2025-04-14T15:03:28.842715Z",
     "iopub.status.idle": "2025-04-14T15:03:28.849140Z",
     "shell.execute_reply": "2025-04-14T15:03:28.848347Z"
    },
    "papermill": {
     "duration": 0.013203,
     "end_time": "2025-04-14T15:03:28.850448",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.837245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_route(state: AgentState) -> Literal[\"ExecuteTool\", \"Respond\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Determines the next node based on the LAST message in the state.\n",
    "    Routes to ExecuteTool if the last message has tool calls,\n",
    "    otherwise routes to Respond to output the message, or ENDs if finished.\n",
    "    \"\"\"\n",
    "    print(\"--- ROUTING ---\")\n",
    "    if state.get(\"final_response_generated\", False):\n",
    "         print(\"   Decision: End of interaction signaled.\")\n",
    "         return END\n",
    "\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "\n",
    "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        print(f\"   Decision: Route to ExecuteTool for calls: {[tc['name'] for tc in last_message.tool_calls]}\")\n",
    "        return \"ExecuteTool\"\n",
    "    elif isinstance(last_message, AIMessage):\n",
    "         print(\"   Decision: Route to END (AI message is final response)\")\n",
    "         return END\n",
    "    elif isinstance(last_message, HumanMessage) and last_message.content.lower().strip() in ['q', 'quit', 'exit', 'goodbye', 'stop']:\n",
    "         print(\"   Decision: End of interaction requested by user.\")\n",
    "         return END\n",
    "    else:\n",
    "         print(\"Fallback\")\n",
    "         return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57ecee",
   "metadata": {
    "papermill": {
     "duration": 0.004298,
     "end_time": "2025-04-14T15:03:28.859526",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.855228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8efd8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:28.869962Z",
     "iopub.status.busy": "2025-04-14T15:03:28.869350Z",
     "iopub.status.idle": "2025-04-14T15:03:38.943511Z",
     "shell.execute_reply": "2025-04-14T15:03:38.942404Z"
    },
    "papermill": {
     "duration": 10.080999,
     "end_time": "2025-04-14T15:03:38.945061",
     "exception": false,
     "start_time": "2025-04-14T15:03:28.864062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not display graph visualization: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\n"
     ]
    }
   ],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"UserInput\", voice_interface_agent)\n",
    "graph_builder.add_node(\"Orchestrator\", orchestrator_agent)\n",
    "\n",
    "tool_executor_node = ToolNode(available_tools)\n",
    "graph_builder.add_node(\"ExecuteTool\", tool_executor_node)\n",
    "\n",
    "graph_builder.add_node(\"Error\", error_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"UserInput\")\n",
    "graph_builder.add_edge(\"UserInput\", \"Orchestrator\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Orchestrator\",\n",
    "    select_route,\n",
    "    {\n",
    "        \"ExecuteTool\": \"ExecuteTool\",\n",
    "        \"Error\": \"Error\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"ExecuteTool\", \"Orchestrator\")\n",
    "\n",
    "graph_builder.add_edge(\"Error\", END)\n",
    "\n",
    "app_graph = graph_builder.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(app_graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"Graph visualization displayed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff66d5",
   "metadata": {
    "papermill": {
     "duration": 0.004394,
     "end_time": "2025-04-14T15:03:38.954820",
     "exception": false,
     "start_time": "2025-04-14T15:03:38.950426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run the Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43327541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:03:38.965136Z",
     "iopub.status.busy": "2025-04-14T15:03:38.964837Z",
     "iopub.status.idle": "2025-04-14T15:03:38.971834Z",
     "shell.execute_reply": "2025-04-14T15:03:38.970958Z"
    },
    "papermill": {
     "duration": 0.014021,
     "end_time": "2025-04-14T15:03:38.973322",
     "exception": false,
     "start_time": "2025-04-14T15:03:38.959301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NODE: Voice Interface ---\n",
      "\n",
      "An error occurred during execution: raw_input was called, but this frontend does not support input requests.\n"
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 15}\n",
    "\n",
    "initial_state = {\"messages\": [], \"final_response_generated\": False}\n",
    "\n",
    "try:\n",
    "    final_state = app_graph.invoke(initial_state, config=config)\n",
    "    print(\"\\n--- Interaction Ended ---\")\n",
    "    print(\"\\nFinal State:\")\n",
    "    pprint(final_state)\n",
    "except Exception as e:\n",
    "     print(f\"\\nAn error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19fc86",
   "metadata": {
    "papermill": {
     "duration": 0.004388,
     "end_time": "2025-04-14T15:03:38.982385",
     "exception": false,
     "start_time": "2025-04-14T15:03:38.977997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 82.107493,
   "end_time": "2025-04-14T15:03:41.763105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T15:02:19.655612",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
